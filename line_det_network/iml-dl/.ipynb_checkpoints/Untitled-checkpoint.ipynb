{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b818e7e-f8db-47e2-a537-3d9ce3a6c3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from core.Trainer import Trainer\n",
    "from time import time\n",
    "import wandb\n",
    "import logging\n",
    "from torchinfo import summary\n",
    "from optim.losses.image_losses import *\n",
    "\n",
    "class PTrainer(Trainer):\n",
    "    def __init__(self, training_params, model, data, device, log_wandb=True):\n",
    "        super(PTrainer, self).__init__(training_params, model, data, device, log_wandb)\n",
    "\n",
    "        for s in self.train_ds:\n",
    "            input_size = s[0].numpy().shape\n",
    "            break\n",
    "        dtypes = [torch.float64]\n",
    "        print(f'Input size of summary is: {input_size}')\n",
    "        summary(model, input_size, dtypes=dtypes)\n",
    "\n",
    "        # Load pre-trained weights if available\n",
    "        pre_trained_weights_path = training_params.get('weights')\n",
    "        if pre_trained_weights_path and os.path.exists(pre_trained_weights_path):\n",
    "            self.model.load_state_dict(torch.load(pre_trained_weights_path))\n",
    "            print(f\"Loaded pre-trained weights from {pre_trained_weights_path}\")\n",
    "\n",
    "    def train(self, model_state=None, opt_state=None, start_epoch=0):\n",
    "        if model_state is not None:\n",
    "            self.model.load_state_dict(model_state)\n",
    "        if opt_state is not None:\n",
    "            self.optimizer.load_state_dict(opt_state)\n",
    "        epoch_losses, epoch_losses_1, epoch_losses_2 = [], [], []\n",
    "        self.early_stop = False\n",
    "        self.model.train()\n",
    "\n",
    "        for epoch in range(self.training_params['nr_epochs']):\n",
    "            print('Epoch: ', epoch)\n",
    "            if start_epoch > epoch:\n",
    "                continue\n",
    "            if self.early_stop is True:\n",
    "                logging.info(\"[Trainer::test]: ################ Finished training (early stopping) ################\")\n",
    "                break\n",
    "            start_time = time()\n",
    "            batch_loss, batch_loss_1, batch_loss_2, count_images = 0, 0, 0, 0\n",
    "\n",
    "            for data in self.train_ds:\n",
    "                kspace = data[0].to(self.device)\n",
    "                target_mask = data[1].to(self.device)\n",
    "\n",
    "                count_images += kspace.shape[0]\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                prediction = self.model(kspace)\n",
    "\n",
    "                loss = self.criterion_rec(target_mask, prediction)\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                batch_loss += loss.item() * kspace.size(0)\n",
    "\n",
    "            epoch_loss = batch_loss / count_images if count_images > 0 else batch_loss\n",
    "            epoch_losses.append(epoch_loss)\n",
    "\n",
    "            end_time = time()\n",
    "            print('Epoch: {} \\tTraining Loss: {:.6f} , computed in {} seconds for {} samples'.format(\n",
    "                epoch, epoch_loss, end_time - start_time, count_images))\n",
    "            wandb.log({\"Train/Loss_\": epoch_loss, '_step_': epoch})\n",
    "\n",
    "            torch.save({'model_weights': self.model.state_dict(), 'optimizer_weights': self.optimizer.state_dict(),\n",
    "                        'epoch': epoch}, self.client_path + '/latest_model.pt')\n",
    "\n",
    "            self.test(self.model.state_dict(), self.val_ds, 'Val', self.optimizer.state_dict(), epoch)\n",
    "\n",
    "        return self.best_weights, self.best_opt_weights\n",
    "\n",
    "    def test(self, model_weights, test_data, task='Val', opt_weights=None, epoch=0):\n",
    "        self.test_model.load_state_dict(model_weights)\n",
    "        self.test_model.to(self.device)\n",
    "        self.test_model.eval()\n",
    "        metrics = {task + '_loss_': 0}\n",
    "        test_total = 0\n",
    "\n",
    "        val_image_available = False\n",
    "        with torch.no_grad():\n",
    "            for data in test_data:\n",
    "                kspace = data[0].to(self.device)\n",
    "                target_mask = data[1].to(self.device)\n",
    "                filename, slice_num = data[2:]\n",
    "\n",
    "                test_total += kspace.shape[0]\n",
    "\n",
    "                prediction = self.test_model(kspace)\n",
    "                prediction_track = prediction.clone().detach()\n",
    "                target_mask_track = target_mask.clone().detach()\n",
    "\n",
    "                loss_bce = self.criterion_rec(target_mask, prediction)\n",
    "\n",
    "                metrics[task + '_loss_'] += loss_bce.item() * kspace.size(0)\n",
    "\n",
    "                if task == 'Val':\n",
    "                    search = [os.path.basename(f) + '_' + str(s.numpy()) for f, s in zip(filename, slice_num)]\n",
    "                    if 'DATA_Epp_4_task-sub-p015_task-calc_acq-fullres_T2star_sim_b0_rigid_1.h5_15' in search:\n",
    "                        ind = np.where(np.array(search) == 'DATA_Epp_4_task-sub-p015_task-calc_acq-fullres_T2star_sim_b0_rigid_1.h5_15')[0][0]\n",
    "                        target_mask_ = target_mask_track[ind]\n",
    "                        prediction_ = prediction_track[ind]\n",
    "                        val_image_available = True\n",
    "\n",
    "            if task == 'Val':\n",
    "                if not val_image_available:\n",
    "                    print('[Trainer - test] ERROR: No validation image can be tracked, since the required filename is '\n",
    "                          'not in the test set')\n",
    "                    print('Using the last available example instead')\n",
    "                    target_mask_ = target_mask_track[0]\n",
    "                    prediction_ = prediction_track[0]\n",
    "\n",
    "                multiclass = False\n",
    "                if len(prediction_.shape) > 1:\n",
    "                    multiclass = True\n",
    "                    prediction_ = torch.argmax(prediction_, axis=0)\n",
    "\n",
    "                prediction_example = prediction_.detach().cpu().numpy().reshape(-1, 92)\n",
    "                target_example = target_mask_.detach().cpu().numpy().reshape(-1, 92)\n",
    "\n",
    "                prediction_example = np.rollaxis(np.tile(prediction_example, (112,1,1)), 0, 3)\n",
    "                target_example = np.rollaxis(np.tile(target_example, (112, 1, 1)), 0, 3)\n",
    "\n",
    "                prediction_example[0, 0, 0] = 0\n",
    "                prediction_example[0, 0, 1] = 1\n",
    "                target_example[0, 0, 0] = 0\n",
    "                target_example[0, 0, 1] = 1\n",
    "\n",
    "                if multiclass:\n",
    "                    prediction_example = prediction_example / 4\n",
    "                    target_example = target_example / 4\n",
    "\n",
    "                prediction_example = prediction_example[0]\n",
    "                target_example = target_example[0]\n",
    "\n",
    "                if len(np.unique(target_example)) < 3:\n",
    "                    if not multiclass:\n",
    "                        thr_prediction = np.zeros_like(prediction_example)\n",
    "                        thr_prediction[prediction_example > 0.5] = 1\n",
    "\n",
    "                pred = wandb.Image(prediction_example[:, ::-1], caption='Predicted corruption mask')\n",
    "                targ = wandb.Image(target_example[:, ::-1], caption='Target corruption mask')\n",
    "                if not multiclass:\n",
    "                    pred_th = wandb.Image(thr_prediction[:, ::-1],\n",
    "                                          caption='Predicted corruption mask (thresholded)')\n",
    "                    wandb.log({task + '/Example_': [pred, pred_th, targ]})\n",
    "                else:\n",
    "                    wandb.log({task + '/Example_': [pred, targ]})\n",
    "\n",
    "            for metric_key in metrics.keys():\n",
    "                metric_name = task + '/' + str(metric_key)\n",
    "                metric_score = metrics[metric_key] / test_total\n",
    "                wandb.log({metric_name: metric_score, '_step_': epoch})\n",
    "            wandb.log({'lr': self.optimizer.param_groups[0]['lr'], '_step_': epoch})\n",
    "            epoch_val_loss = metrics[task + '_loss_'] / test_total\n",
    "            if task == 'Val':\n",
    "                print('Epoch: {} \\tValidation Loss: {:.6f} , computed for {} samples'.format(\n",
    "                    epoch, epoch_val_loss, test_total))\n",
    "                if epoch_val_loss < self.min_val_loss:\n",
    "                    self.min_val_loss = epoch_val_loss\n",
    "                    torch.save({'model_weights': model_weights, 'optimizer_weights': opt_weights, 'epoch': epoch},\n",
    "                               self.client_path + '/best_model.pt')\n",
    "                    self.best_weights = model_weights\n",
    "                    self.best_opt_weights = opt_weights\n",
    "                self.early_stop = self.early_stopping(epoch_val_loss)\n",
    "                if self.lr_scheduler is not None:\n",
    "                    self.lr_scheduler.step(epoch_val_loss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
